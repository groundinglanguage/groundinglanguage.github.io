<!doctype html>

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <!-- <script src="https://distill.pub/template.v2.js"></script> -->
  <script src="lib/template.v2.js"></script>
  <script src="lib/blazy.js"></script>
  <script>
    var bLazy = new Blazy({
        success: function(){
            updateCounter();
        }
    });
    var imageLoaded = 0;
    function updateCounter() {
        imageLoaded++;
        console.log("blazy image loaded: "+imageLoaded);
    }
  </script>


  <style>
  </style>
</head>

<body>

  <d-front-matter>
    <script type="text/json">{
      "title": "Grounding Language in Play",
      "description": "Learning natural language conditioned control from play.",
      "authors": [
      ],
      "katex": {
        "delimiters": [
          {
            "left": "$",
            "right": "$",
            "display": false
          },
          {
            "left": "$$",
            "right": "$$",
            "display": true
          }
        ]
      }
    }</script>
  </d-front-matter>

  <style>
    figure {
      text-align: center;
      margin-bottom: 0.5em;
      margin-top: 0.5em;
    }
    figure img {
      max-width: 100%;
      width: unset;
    }
    video {
      max-width: 100%;
    }
    .colab-root {
      display: inline-block;
      background: rgba(255, 255, 255, 0.75);
      padding: 4px 8px;
      border-radius: 4px;
      font-size: 11px!important;
      text-decoration: none;
      color: #aaa;
      border: none;
      font-weight: 300;
      border: solid 1px rgba(0, 0, 0, 0.08);
      border-bottom-color: rgba(0, 0, 0, 0.15);
      text-transform: uppercase;
      line-height: 16px;
    }

   span.colab-span {
      background-image: url();
      background-repeat: no-repeat;
      background-size: 20px;
      background-position-y: 2px;
      display: inline-block;
      padding-left: 24px;
      border-radius: 4px;
      text-decoration: none;
    }

    a.colab-root:hover{
      color: #666;
      background: white;
      border-color: rgba(0, 0, 0, 0.2);
    }

    /* TOC */
    @media(max-width: 1000px){
      d-contents {
        justify-self: start;
        align-self: start;
        grid-column-start: 2;
        grid-column-end: 6;
        padding-bottom: 0.5em;
        margin-bottom: 1em;
        padding-left: 0.25em;
        border-bottom: 1px solid rgba(0, 0, 0, 0.1);
        border-bottom-width: 1px;
        border-bottom-style: solid;
        border-bottom-color: rgba(0, 0, 0, 0.1);
      }
    }

    @media (min-width: 1000px){
      d-contents {
        align-self: start;
        grid-column-start: 1;
        grid-column-end: 4;
        justify-self: end;
        padding-right: 3em;
        padding-left: 2em;
        border-right: 1px solid rgba(0, 0, 0, 0.1);
        border-right-width: 1px;
        border-right-style: solid;
        border-right-color: rgba(0, 0, 0, 0.1);
      }
    }

    @media (min-width: 1180px){
      d-contents {
        grid-column-start: 1;
        grid-column-end: 4;
        justify-self: end;
        padding-right: 3em;
        padding-left: 2em;
        border-right: 1px solid rgba(0, 0, 0, 0.1);
        border-right-width: 1px;
        border-right-style: solid;
        border-right-color: rgba(0, 0, 0, 0.1);
      }
    }

    d-contents nav h3 {
      margin-top: 0;
      margin-bottom: 1em;
    }

    d-contents nav a {
      color: rgba(0, 0, 0, 0.8);
      border-bottom: none;
      text-decoration: none;
    }

    d-contents li {
      list-style-type: none;
    }

    d-contents ul {
      padding-left: 1em;
    }

    d-contents nav ul li {
      margin-bottom: .25em;
    }

    d-contents nav a:hover {
      text-decoration: underline solid rgba(0, 0, 0, 0.6);
    }

    d-contents nav ul {
      margin-top: 0;
      margin-bottom: 6px;
    }


    d-contents nav>div {
      display: block;
      outline: none;
      margin-bottom: 0.5em;
    }

    d-contents nav>div>a {
      font-size: 13px;
      font-weight: 600;
    }

    d-contents nav>div>a:hover,
    d-contents nav>ul>li>a:hover {
        text-decoration: none;
    }

    /* code blocks to margins */
    @media (min-width: 1600px) {
      d-code {
        margin-top: -10px;
        grid-column-start: 12;
        grid-column-end: 14; 
      }
    }
    /* /\* so title is on one line *\/ */
    /* d-title h1, d-title p { */
    /*   grid-column: middle; */
    /* } */

  </style>
  <script>
  // hack to edit font size in code snippets. guaranteed a better way to do 
  // this, but I'm not a webdev
  window.onload = function() {
    setTimeout(() => { document.querySelectorAll("d-code").forEach(function(e) {e.shadowRoot.querySelector('#code-container').style.fontSize = "0.7em"}); }, 3000);
  }
  </script>

<!-- title section -->
<d-title>
  <h1>Grounding Language in Play</h1>
  <!-- <p>Combining open-ended robotic manipulation with open-ended human language conditioning</p> -->
  <p>A scalable approach for controlling robots with natural language</p>
  <!-- <p>Scalable human language conditioned visual control</p> -->
  <!--   <\!-- menu on the left -\-> -->
  <!-- <d-contents> -->
  <!-- <nav class="l-text toc figcaption"> -->
  <!--   <div><a href="https://arxiv.org/pdf/2005.TODO.pdf">pdf</a></div> -->
  <!--   <div><a href="#citation">bibtex</a></div> -->
  <!-- </nav> -->
  <!-- </d-contents> -->

  <!-- video -->
  <div class="l-body" id="demo">
  <figure>

    <video class="b-lazy" loop autoplay playsinline muted style="display: block; width: 80%; margin:0 auto"
           data-src="videos/live/playlang_20200326-193259_13tasks_bt300k.mp4" type="video/mp4">
      Your browser does not support the video tag.
    </video>
  <figcaption>
  <b>Video 1.</b> Our agent following real-time human language instructions.</b>
  </figcaption>
  </figure>
  </div>

</d-title>

<!-- <d-byline> -->
<!--   <div class="byline grid"> -->
<!--     <div class="authors-affiliations grid"> -->
<!--     </div> -->
<!--     <div> -->
<!--       <h3>Published</h3> -->
<!--     </div> -->
<!--     <div> -->
<!--       <h3>Links</h3> -->
<!--     </div> -->
<!--   </div> -->
<!-- </d-byline> -->

<d-article>

<!-- <d-contents> -->
<!--   <nav class="l-text toc figcaption"> -->
<!--     <h3>Contents</h3> -->
<!--     <div><a href="#introduction">1. Introduction</a></div> -->
<!--       <ul><li><a href="#demo"><u>Video 1:</u> Following human language instructions</a></li></ul> -->
<!--       <\!-- <ul><li><a href="#multilingual_teaser"><u>Video 2:</u> Zero shot instructions, 16 languages</a></li></ul> -\-> -->
<!--     <div><a href="#related">2. Related Work</a></div> -->
<!--     <div><a href="#preliminaries">3. Preliminaries</a></div> -->
<!--     <\!-- <ul> -\-> -->
<!--     <\!--   <li><a href="#prelim1">3.1 Relabeled imitation learning</a></li> -\-> -->
<!--     <\!--   <li><a href="#prelim2">3.2 Teleoperated play</a></li> -\-> -->
<!--     <\!--   <li><a href="#prelim3">3.3 Learning from play</a></li> -\-> -->
<!--     <\!-- </ul> -\-> -->
<!--     <div><a href="#sec:4">4. Learning to Follow Human Language Instructions</a></div> -->
<!--     <ul> -->
<!--       <li><a href="#sec:hip">4.1 Pairing robot experience with language</a></li> -->
<!--       <ul><li><a href="#video:data"><u>Video 3:</u> Training Data</a></li></ul> -->
<!--       <li><a href="#sec:mcil">4.2 Multicontext Imitation Learning</a></li> -->
<!--       <li><a href="#sec:lang_lfp">4.3 LangLfP: following image and language goals.</a></li> -->
<!--       <li><a href="#sec:transfer_lang_lfp">4.4 Transferring knowledge from text corpora</a></li> -->
<!--     </ul> -->
<!--     <div><a href="#experimental_setup">5. Experimental Setup</a></div> -->
<!--     <\!-- <ul> -\-> -->
<!--     <\!--   <li><a href="#sec:sim_env">5.1 3D simulated environment</a></li> -\-> -->
<!--     <\!--   <li><a href="#sec:methods">5.2 Methods</a></li> -\-> -->
<!--     <\!-- </ul> -\-> -->
<!--     <div><a href="#ama">6. "Ask Me Anything" Experiments</a></div> -->
<!--     <ul> -->
<!--       <li><a href="#sec:long_horizon_eval">6.1 Long-Horizon Evaluation</a></li> -->
<!--       <li><a href="#sec:long_horizon_results">6.2 Long Horizon Results</a></li> -->
<!--       <ul> -->
<!--         <li><a href="#qualitative-langlfp"><u>Video 4:</u> Test time human language conditioned visual control</a></li> -->
<!--         <li><a href="#lfp-vs-bc"><u>Video 5:</u> Play vs. conventional demonstrations</a></li> -->
<!--         <li><a href="#15tasks"><u>Video 6:</u> 15 tasks in a row</a></li> -->
<!--         <li><a href="#human_assistance"><u>Video 7:</u> Language unlocks human assistance</a></li> -->
<!--         <li><a href="#ood_tasks"><u>Video 8:</u> Composing new tasks with language</a></li> -->
<!--       </ul> -->
<!--     </ul> -->
<!--     <div><a href="#transfer">7. Knowledge Transfer Experiments</a></div> -->
<!--     <ul> -->
<!--       <li><a href="#multilingual"><u>Video 9:</u> Transfer unlocks zero shot instruction following</a></li> -->
<!--     </ul> -->
<!--     <div><a href="#future">8. Limitations and Future Work</a></div> -->
<!--     <div><a href="#conclusion">9. Conclusion</a></div> -->
<!--     <div><a href="#appendix">Appendix</a></div> -->
<!-- <\!--     <ul> -->
<!--       <li><a href="#relabeling">A. Relabeling play</a></li> -->
<!--       <li><a href="#sec:appendix_architecture">B. LangLfP Implementation Details</a></li> -->
<!--       <li><a href="#sec:appendix_env">C. Environment</a></li> -->
<!--       <li><a href="#sec:appendix_dataset">D. Datasets</a></li> -->
<!--       <li><a href="#sec:appendix_models">E. Models</a></li> -->
<!--       <li><a href="#sec:appendix_eval">F. Long Horizon Evaluation</a></li> -->
<!--       <li><a href="#sec:qualitative_examples">G. Qualitative Examples</a></li> -->
<!--       <ul> -->
<!--         <li><a href="#ood_tasks"><u>Videos:</u>Tasks not present in the 18-task benchmark</a></li> -->
<!--       </ul> -->
<!--       <li><a href="#ablation">H. Ablation: How much language is necessary?</a></li> -->
<!--     </ul> -\-> -->
<!-- <\!--     <div><a href="#acknowledgments">Acknowledgments</a></div> -->
<!--     <div><a href="#references">References</a></div> -->
<!--  -\-> -->
<!--     <\!-- <ul> -\-> -->

      
<!--     <\!--   <li><a href="#long-horizon">15 tasks in a row</a></li> -\-> -->
<!--     <\!--   <li><a href="#lfp-vs-bc">Learning from play vs demonstrations</a></li> -\-> -->
<!--     <\!--   <li><a href="#multilingual">Multi-lingual inputs</a></li> -\-> -->
<!--     <\!--   <li><a href="#transfer">Knowledge transfer via language</a></li> -\-> -->
<!--     <\!--   <li><a href="#repeated">Repeated instructions</a></li> -\-> -->
<!--     <\!--   <li><a href="#ood_tasks">Tasks not in benchmark</a></li> -\-> -->
<!--     <\!--   <li><a href="#interactive">Operator can help robot</a></li> -\-> -->
<!--     <\!--   <li><a href="#failures">Failure cases</a></li> -\-> -->
<!--     <\!--   <li><a href="#more_examples">Short sequences</a></li> -\-> -->
<!--     <\!-- </ul> -\-> -->
<!--   </nav> -->
<!-- </d-contents> -->

<!-- starting article -->


      <!-- <figure id="multilingual_teaser"> -->
      <!--   <video id="video:2" class="b-lazy" loop autoplay playsinline muted style="display: block; width: 80%; margin:0 auto" data-src="videos/languages/multilingual_bt300k.mp4" type="video/mp4"></video> -->
      <!--   <figcaption><b>Video 2: Following out-of-distribution instructions in zero shot, in 16 languages.</b></figcaption> -->
      <!-- </figure> -->


<h3 id="sec:4">4. Learning to Follow Human Language Instructions</h3>
<h4 id="sec:hip">4.1 Pairing robot experience with human language</h4>

<figure>
<video id="video:data" class="b-lazy" loop autoplay playsinline muted style="display: block; width: 70%; margin:0 auto" data-src="videos/data/playground_all_32_sequences_6_bt300k.mp4" type="video/mp4"></video>
  <figcaption>
  <b>Video 3. Examples of our training data:</b> We sample random experiences from teleoperated play, then ask humans: "what instruction would you give the agent to get from first frame to last frame?" 
  </figcaption>
</figure>


<h3 id="ama">6. "Ask Me Anything" Experiments</h3>

<h4 id="sec:long_horizon_eval">6.1 Long-Horizon Evaluation</h4>

<p id="qualitative-langlfp"><b>Video 4: Test time human language conditioned visual control</b>. Here are examples of LangLfP following human instructions at test time from onboard observations. See more qualitative examples in <a href="#sec:qualitative_examples">Appendix G</a>.</p>
<figure>
<video class="b-lazy" loop autoplay playsinline muted style="display: block; width: 88%; margin:0 auto" data-src="videos/pixels/long_chains/long_chains_drawer-sweep-grasp_lift-close_drawer_iter96001_chain_demo0_lang-en_trial16_success1.0.mp4_frames_bt300k.mp4" type="video/mp4"></video>
<!-- <figcaption>
  LangLfP solves natural language specified tasks from onboard observations.
</figcaption> -->
</figure>

<figure>
<video class="b-lazy" loop autoplay playsinline muted style="display: block; width: 88%; margin:0 auto" data-src="videos/pixels/long_chains/long_chains_put_in_shelf-pull_out_shelf-put_in_shelf-pull_out_shelf-grasp_flat_iter64001_chain_demo0_lang-en_trial22_success1.0.mp4_frames_bt300k.mp4" type="video/mp4"></video>
<!-- <figcaption>
  LangLfP solves natural language specified tasks from onboard observations.
</figcaption> -->
</figure>

<figure>
<video class="b-lazy" loop autoplay playsinline muted style="display: block; width: 88%; margin:0 auto" data-src="videos/pixels/long_chains/long_chains_drawer-sweep-close_drawer-sliding-push_green-push_blue-push_red-close_sliding-drawer-close_drawer-sliding-drawer_iter128001_chain_demo0_lang-en_trial29_success1.0.mp4_frames_bt300k.mp4" type="video/mp4"></video>
<!-- <figcaption>
  LangLfP solves natural language specified tasks from onboard observations.
</figcaption> -->
</figure>

<h4 id="sec:long_horizon_results">6.2 Long Horizon Results</h4>

<p id="lfp-vs-bc"><b>Video 5: Play vs. conventional demonstrations</b>. Here we qualitatively compare LangLfP to LangBC by providing each with the exact same set of 4 instructions.</p>

<div class="l-page-outset" id="lfpvsbc_table">
<table border="0" cellpadding="5" style="text-align: center">
  <tr>
    <td><big><b>LangLfP</b></big></td>
    <td><big><b>LangBC</b></big></td>
  </tr>
  <tr>
    <td>
      <figure>
      <video class="b-lazy" loop autoplay playsinline muted style="display: block; width: 100%; margin:0 auto" data-src="videos/chain4/chain4_lfp_drawer-sweep-close_drawer-sliding_bt300k.mp4" type="video/mp4"></video>
      </figure>
    </td>
    <td>
      <figure>
      <video class="b-lazy" loop autoplay playsinline muted style="display: block; width: 100%; margin:0 auto" data-src="videos/chain4/chain4_bc_drawer-sweep-close_drawer-sliding_bt300k.mp4" type="video/mp4"></video>
      </figure>
    </td>
  </tr>
  <tr>
     <td colspan=2><small>
     Instructions:
      1) "pull the drawer handle all the way"
      2) "put the block in to the drawer"
      3) "push the drawer in"
      4) "move the door all the way right"
      <br><br></small>
    </td>
  </tr>
 
  

  <tr>
    <td><big><b>LangLfP</b></big></td>
    <td><big><b>LangBC</b></big></td>
  </tr>
  <tr>
    <td>
      <figure>
      <video class="b-lazy" loop autoplay playsinline muted style="display: block; width: 100%; margin:0 auto" data-src="videos/chain4/chain4_lfp_pull_out_shelf-sliding-push_blue-close_sliding_bt300k.mp4" type="video/mp4"></video>
      </figure>
    </td>
    <td>
      <figure>
      <video class="b-lazy" loop autoplay playsinline muted style="display: block; width: 100%; margin:0 auto" data-src="videos/chain4/chain4_bc_pull_out_shelf-sliding-push_blue-close_sliding_bt300k.mp4" type="video/mp4"></video>
      </figure>
    </td>
  </tr>
  <tr>
     <td colspan=2><small>
     Instructions:
      1) "drag the block out"
      2) "push the door to the right"
      3) "press blue"
      4) "move the door all the way left"
      <br><br></small>
    </td>
  </tr>

  <tr>
    <td><big><b>LangLfP</b></big></td>
    <td><big><b>LangBC</b></big></td>
  </tr>
  <tr>
    <td>
      <figure>
      <video class="b-lazy" loop autoplay playsinline muted style="display: block; width: 100%; margin:0 auto" data-src="videos/chain4/chain4_lfp_knock-drawer-sweep-close_drawer_bt300k.mp4" type="video/mp4"></video>
      </figure>
    </td>
    <td>
      <figure>
      <video class="b-lazy" loop autoplay playsinline muted style="display: block; width: 100%; margin:0 auto" data-src="videos/chain4/chain4_bc_knock-drawer-sweep-close_drawer_bt300k.mp4" type="video/mp4"></video>
      </figure>
    </td>
  </tr>
  <tr>
     <td colspan=2><small>
     Instructions:
      1) "knock the object"
      2) "pull the drawer handle all the way"
      3) "drag the object into the drawer"
      4) "close the drawer"
      <br><br></small>
    </td>
  </tr>
  
</table>
</div>


<p id="15tasks"><b>Following 15 instructions in a row.</b>
</p>

<figure>
  <video id="long-horizon" class="b-lazy" loop autoplay playsinline muted style="display: block; width: 70%; margin:0 auto" data-src="videos/long/chain15_iter52001_chain_demo0_lang-en_trial4_success1.0.mp4_frames_bt300k.mp4" type="video/mp4">
      Your browser does not support the video tag.
  </video>
  <figcaption>
  <b>Video 6. LangLfP follows 15 instructions in a row.</b>
  </figcaption>
</figure>


<p id="human_assistance"><b>Language unlocks human assistance.</b>

<figure>
<video id="interactive" class="b-lazy" loop autoplay playsinline muted style="display: block; width: 70%; margin:0 auto" data-src="videos/live/playlang_20200326-191101_interaction_bt300k.mp4" type="video/mp4"></video>
<figcaption>
<b>Video 7: Interactive human language assistance: </b>The operator offers real time language guidance to the robot whose end-effector gets stuck, allowing it to solve for "press the red button".
</figcaption>
</figure>


<p id="ood_tasks"><b>Video 8: Composing new tasks with language</b>.

<div class="l-page-outset" id="ood_tasks_table">
<table border="0" cellpadding="5" style="text-align: center">
  <tr>
    <td>
      <figure>
      <video id="fig:trash" class="b-lazy" loop autoplay playsinline muted style="display: block; width: 100%; margin:0 auto" data-src="videos/live/playlang_20200325-154140_trash_bt300k.mp4" type="video/mp4"></video>
      <figcaption><b>Putting the object in the trash:</b> An operator is able to put the object in the trash by breaking down the task into 2 smaller subtasks with the following sentences; 1) "pick up the object" 2) "put the object in the trash".</figcaption>
      </figure>
    </td>
    <td>
      <figure>
      <video id="fig:top_of_shelf" class="b-lazy" loop autoplay playsinline muted style="display: block; width: 100%; margin:0 auto" data-src="videos/live/playlang_20200325-162306_top_shelf_bt300k.mp4" type="video/mp4"></video>
      <figcaption><b>Putting the object on top of the shelf:</b> An operator is able to put the object in the trash by breaking down the task into 2 smaller subtasks with the following sentences; 1) "pick up the object" 2) "put the object on top of the shelf".</figcaption>
      </figure>
    </td>
  </tr>
</table>
</div>

<h3 id="transfer">7. Knowledge Transfer Experiments</h3>

<h4>7.1 Knowledge Transfer Results</h4>

<p id="multilingual"><b>Video 9: Transfer unlocks zero shot instruction following</b></p>

<!-- <\!-- <div class="l-body" id="demo"> -\-> -->
<!-- <figure> -->

  <video class="b-lazy" loop autoplay playsinline muted style="display: block; width: 80%; margin:0 auto"
         data-src="videos/languages/multilingual_bt300k.mp4" type="video/mp4">
    Your browser does not support the video tag.
  </video>
<figcaption>
<b>Following instructions in 16 different languages</b>
</figcaption>
</figure>
<!-- </div> -->

<!-- <div class="l-body" id="demo"> -->
<figure>

  <video class="b-lazy" loop autoplay playsinline muted style="display: block; width: 80%; margin:0 auto"
         data-src="videos/languages/playlang_20200327-141234_fr_bin_bt300k.mp4" type="video/mp4">
    Your browser does not support the video tag.
  </video>
<figcaption>
<b>Real-time instructions in French, even though agent only trained with English.</b> 6 instructions: "open the drawer... put the object into the drawer...take the object out of the drawer...close the drawer...grasp the object...put the object in the bin."
</figcaption>
</figure>


<h3 id="future">8. Failure examples</h3>

<figure id="failure1">
<video class="b-lazy" loop autoplay playsinline muted style="display: block; width: 88%; margin:0 auto" data-src="videos/pixels/failures/failures_knock-grasp_flat_iter182001_chain_demo0_lang-en_trial3_success0.5.mp4_frames_bt300k.mp4" type="video/mp4"></video>
<figcaption>
Failure: The agent times out attempting to lift the block.
</figcaption>
</figure>

<figure id="failure2">
<video class="b-lazy" loop autoplay playsinline muted style="display: block; width: 88%; margin:0 auto" data-src="videos/pixels/failures/failures_put_in_shelf-sliding_iter182001_chain_demo1_lang-en_trial2_success0.0.mp4_frames_bt300k.mp4" type="video/mp4"></video>
<figcaption>
Failure: The agent encounters an arm configuration likely avoided by human operators during teleoperated play, leading to compounding error.
</figcaption>
</figure>

<!-- appendix -------------------------------------------------------------------------------------------------------------------- -->

<h2 id="appendix">Appendix</h2>

<h3 id="sec:qualitative_examples">G. Qualitative Examples</h3>

<h4 id="repeated">Repeated Instructions</h4>

Here we demonstrate repetitions of the same pair of actions multiple times: on the left the input sentences ("pick up the object and drop it vertically", "knock the object") is are performed twice in a row, on the right the ("open the drawer", "close the drawer") instructions are repeated 3 times in a row:

<div class="l-page-outset" id="transfer_table">
<table border="0" cellpadding="5" style="text-align: center">
  <tr>
    <td>
      <figure>
      <video class="b-lazy" loop autoplay playsinline muted style="display: block; width: 100%; margin:0 auto" data-src="videos/live/playlang_20200326-114030_knock2_bt300k.mp4" type="video/mp4"></video>
      <figcaption>(upright object, knock object) x 2</figcaption>
      </figure>
    </td>
    <td>
      <figure>
      <video class="b-lazy" loop autoplay playsinline muted style="display: block; width: 100%; margin:0 auto" data-src="videos/live/playlang_20200326-184425_open-close-drawer-3x_bt300k.mp4" type="video/mp4"></video>
      <figcaption>(open drawer, close drawer) x 3</figcaption>
      </figure>
    </td>
  </tr>
  <tr>
    <td>
      <figure>
      <video class="b-lazy" loop autoplay playsinline muted style="display: block; width: 100%; margin:0 auto" data-src="videos/repeat/reapeat_iter52001_chain_demo0_lang-en_trial22_success1.0.mp4_frames_bt300k.mp4" type="video/mp4"></video>
      <figcaption>object (in, out) of shelf x 2</figcaption>
      </figure>
    </td>
    <td>
    </td>
  </tr>
</table>
</div>

<h4 id="more_examples">More examples of compound instructions</h4>

<figure>
<video class="b-lazy" loop autoplay playsinline muted style="display: block; width: 88%; margin:0 auto" data-src="videos/pixels/chain2/chain2_grasp_lift-close_drawer_iter182001_chain_demo0_lang-en_trial0_success1.0.mp4_frames_bt300k.mp4" type="video/mp4"></video>
<figcaption>
</figcaption>
</figure>

<figure>
<video class="b-lazy" loop autoplay playsinline muted style="display: block; width: 88%; margin:0 auto" data-src="videos/pixels/chain2/chain2_put_in_shelf-sliding_iter182001_chain_demo2_lang-en_trial0_success1.0.mp4_frames_bt300k.mp4" type="video/mp4"></video>
<figcaption>
</figcaption>
</figure>

<figure>
<video class="b-lazy" loop autoplay playsinline muted style="display: block; width: 88%; margin:0 auto" data-src="videos/pixels/chain2/chain2_sweep-grasp_lift_iter182001_chain_demo0_lang-en_trial2_success1.0.mp4_frames_bt300k.mp4" type="video/mp4"></video>
<figcaption>
</figcaption>
</figure>

<figure>
  <video class="b-lazy" loop autoplay playsinline muted style="display: block; width: 88%; margin:0 auto" data-src="videos/pixels/chain2/chain2_sweep_right-grasp_flat_iter182001_chain_demo0_lang-en_trial4_success1.0.mp4_frames_bt300k.mp4" type="video/mp4"></video>
<figcaption>
</figcaption>
</figure>


<h3 id="transferlanglfp_vs_langlfp">I. Knowledge transfer with language pretraining</h3>
TransferLangLfP, trained on top of multilingual language embeddings, is able to follow instructions in 16 different languages in zero shot. LangLfP, which learns language from scratch, can only follow English instructions it was trained on. We see when presented with cross-lingual inputs, LangLfP resorts to outputting maximum likelihood play actions. TransferLangLfP, on the other hand, correctly solves tasks.

<div class="l-page-outset" id="transfer_table">
<table border="0" cellpadding="0" style="text-align: center">
  <tr>
    <td><big><b>TransferLangLfP</b></big><br>(understands 16 languages)</td>
    <td><big><b>LangLfP</b></big><br>(only understands english)</td>
  </tr>
  <tr>
    <td>
      <figure>
      <video class="b-lazy" loop autoplay playsinline muted style="display: block; width: 100%; margin:0 auto" data-src="videos/pixels/ood_lfpt/ood_lfpt_close_drawer-drawer-sweep-close_drawer_iter182001_chain_demo0_lang-fr_trial1_success1.0.mp4_frames_bt300k.mp4" type="video/mp4"></video>
      </figure>
    </td>
    <td>
      <figure>
      <video class="b-lazy" loop autoplay playsinline muted style="display: block; width: 100%; margin:0 auto" data-src="videos/pixels/ood_lfp/ood_lfp_close_drawer-drawer-sweep-close_drawer_iter330001_chain_demo0_lang-fr_trial1_success0.0.mp4_frames_bt300k.mp4" type="video/mp4"></video>
      </figure>
    </td>
  </tr>
  <tr>
     <td colspan=2><small>
     Input sentences:
      1. close the drawer all the way
      2. pull the drawer handle all the way
      3. drag the object into the drawer
      4. close the drawer
      <br><br></small>
    </td>
  </tr>

  <tr>
    <td>
      <figure>
      <video class="b-lazy" loop autoplay playsinline muted style="display: block; width: 100%; margin:0 auto" data-src="videos/pixels/ood_lfpt/ood_lfpt_close_drawer-sliding-push_green-close_sliding_iter182001_chain_demo0_lang-ja_trial2_success1.0.mp4_frames_bt300k.mp4" type="video/mp4"></video>
      </figure>
    </td>
    <td>
      <figure>
      <video class="b-lazy" loop autoplay playsinline muted style="display: block; width: 100%; margin:0 auto" data-src="videos/pixels/ood_lfp/ood_lfp_close_drawer-sliding-push_green-close_sliding_iter330001_chain_demo0_lang-ja_trial3_success0.2.mp4_frames_bt300k.mp4" type="video/mp4"></video>
      </figure>
    </td>
  </tr>
  <tr>
     <td colspan=2><small>
     Input sentences:
      1. close the drawer all the way
      2. push the door to the right
      3. press green
      4. move the door all the way left
      <br><br></small>
    </td>
  </tr>
  
</table>
</div>



<h3 id="failures">J. More Failure Cases</h3>


<figure>
<video class="b-lazy" loop autoplay playsinline muted style="display: block; width: 88%; margin:0 auto" data-src="videos/pixels/failures/failures_sweep-grasp_lift_iter182001_chain_demo1_lang-en_trial5_success0.5.mp4_frames_bt300k.mp4" type="video/mp4"></video>
<figcaption>
The agent times out attempting to lift the block from the drawer.
</figcaption>
</figure>

<figure>
<video class="b-lazy" loop autoplay playsinline muted style="display: block; width: 88%; margin:0 auto" data-src="videos/pixels/failures/failures_sweep_right-grasp_flat_iter182001_chain_demo1_lang-en_trial1_success0.0.mp4_frames_bt300k.mp4" type="video/mp4"></video>
<figcaption>
The agent encounters an arm configuration likely avoided during teleoperated play, leading to compounding error.
</figcaption>
</figure>

<figure>
<video class="b-lazy" loop autoplay playsinline muted style="display: block; width: 70%; margin:0 auto" data-src="videos/failures/iter52001_chain_demo0_lang-en_trial5_success1.0.mp4_frames_bt300k.mp4" type="video/mp4"></video>
<figcaption>
The agent makes several incorrect choices on the way to solving a task.
</figcaption>
</figure>


</d-article>



</body>
